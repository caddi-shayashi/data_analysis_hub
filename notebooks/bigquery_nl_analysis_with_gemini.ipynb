{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery Natural Language Analysis with Gemini\n",
    "\n",
    "このノートブックでは、Gemini APIを使用してBigQueryのSalesforceデータを自然言語で分析します。\n",
    "\n",
    "## 使用モデル（2025年1月最新）\n",
    "- **Gemini 2.5 Pro** (gemini-2.5-pro-exp-0117): データ分析最適化モデル\n",
    "  - 最大200万トークンの長大なコンテキスト処理\n",
    "  - 高精度なSQL生成と複雑な推論\n",
    "  - 大規模データセットの一括分析\n",
    "  - RAG（Retrieval-Augmented Generation）対応\n",
    "  \n",
    "- フォールバックモデル:\n",
    "  - **Gemini 2.5 Flash** (gemini-2.5-flash-exp-0117): 高速バランス版\n",
    "  - **Gemini 2.0 Flash** (gemini-2.0-flash-exp-01-21): 超高速処理版\n",
    "\n",
    "## 対象テーブル\n",
    "- `esperanto-drawer-prod.dm_business_planning.salesforce_account_mart`\n",
    "- `esperanto-drawer-prod.dm_business_planning.salesforce_opportunity_mart`\n",
    "\n",
    "## API Key設定方法\n",
    "\n",
    "### Google Colabの場合（推奨）\n",
    "1. Colabノートブックの左メニューから「🔑」（シークレット）アイコンをクリック\n",
    "2. 「新しいシークレットを追加」をクリック\n",
    "3. 名前に `GEMINI_API_KEY` を入力\n",
    "4. 値にGemini API Keyを貼り付け\n",
    "5. 「ノートブックからのアクセスを許可」をONにする\n",
    "\n",
    "### ローカル環境の場合\n",
    "環境変数 `GEMINI_API_KEY` に設定するか、実行時に入力プロンプトが表示されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境設定とライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. 環境設定とライブラリのインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Google Cloud認証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m auth\n\u001b[32m      2\u001b[39m auth.authenticate_user()\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m認証完了\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "print('認証完了')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. API設定と初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.generativeai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcloud\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m bigquery\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenerativeai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgenai\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.generativeai'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.cloud import bigquery\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Gemini API キーの設定\n",
    "# Colabのシークレットから取得 (Colab環境の場合)\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
    "    print('Colabシークレットから API Key を取得しました')\n",
    "except:\n",
    "    # Colabシークレット以外の環境変数から取得\n",
    "    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "    if not GEMINI_API_KEY:\n",
    "        # 環境変数にもない場合は手動入力\n",
    "        from getpass import getpass\n",
    "        GEMINI_API_KEY = getpass('Gemini API Key を入力してください: ')\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# BigQueryクライアントの初期化\n",
    "PROJECT_ID = 'esperanto-drawer-prod'\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Geminiモデルの初期化\n",
    "# gemini-2.5-pro-exp-0117: 2025年1月時点の最新プロモデル\n",
    "# - 最大200万トークンのコンテキスト長\n",
    "# - データ分析・SQL生成に最適\n",
    "# - 複雑な推論と高精度な分析が可能\n",
    "try:\n",
    "    model = genai.GenerativeModel('gemini-2.5-pro-exp-0117')\n",
    "    print('初期化完了')\n",
    "    print(f'使用モデル: gemini-2.5-pro-exp-0117 (最新データ分析特化版)')\n",
    "except:\n",
    "    # フォールバック1: 2.5 Flash (高速性と精度のバランス)\n",
    "    try:\n",
    "        model = genai.GenerativeModel('gemini-2.5-flash-exp-0117')\n",
    "        print('初期化完了')\n",
    "        print(f'使用モデル: gemini-2.5-flash-exp-0117 (高速バランス版)')\n",
    "    except:\n",
    "        # フォールバック2: 2.0 Flash (さらに高速)\n",
    "        model = genai.GenerativeModel('gemini-2.0-flash-exp-01-21')\n",
    "        print('初期化完了')\n",
    "        print(f'使用モデル: gemini-2.0-flash-exp-01-21 (超高速版)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. テーブルスキーマの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def get_table_schema(dataset_id: str, table_id: str) -> pd.DataFrame:\n    \"\"\"テーブルのスキーマ情報を取得\"\"\"\n    # COLUMNS テーブルを使用（より標準的）\n    query = f\"\"\"\n    SELECT \n        column_name,\n        data_type,\n        IFNULL(description, '') as description\n    FROM `{PROJECT_ID}.{dataset_id}.INFORMATION_SCHEMA.COLUMNS`\n    WHERE table_name = '{table_id}'\n    ORDER BY column_name\n    \"\"\"\n    try:\n        return client.query(query).to_dataframe()\n    except Exception as e:\n        print(f\"COLUMNS使用時のエラー: {e}\")\n        # フォールバック: COLUMN_FIELD_PATHSを使用\n        query_fallback = f\"\"\"\n        SELECT \n            column_name,\n            data_type,\n            IFNULL(description, '') as description\n        FROM `{PROJECT_ID}.{dataset_id}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n        WHERE table_name = '{table_id}'\n        ORDER BY column_name\n        \"\"\"\n        return client.query(query_fallback).to_dataframe()\n\n# スキーマ情報を取得\naccount_schema = get_table_schema('dm_business_planning', 'salesforce_account_mart')\nopportunity_schema = get_table_schema('dm_business_planning', 'salesforce_opportunity_mart')\n\nprint(\"Account Mart カラム数:\", len(account_schema))\nprint(\"Opportunity Mart カラム数:\", len(opportunity_schema))\n\n# 主要カラムを表示\nprint(\"\\n=== Account Mart 主要カラム ===\")\ndisplay(account_schema.head(10))\n\nprint(\"\\n=== Opportunity Mart 主要カラム ===\")\ndisplay(opportunity_schema.head(10))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 自然言語→SQL変換クラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLToBigQueryAnalyzer:\n",
    "    def __init__(self, client: bigquery.Client, model):\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "        self.account_schema = account_schema\n",
    "        self.opportunity_schema = opportunity_schema\n",
    "        \n",
    "    def generate_sql(self, natural_language_query: str) -> str:\n",
    "        \"\"\"自然言語クエリからSQLを生成\"\"\"\n",
    "        \n",
    "        # スキーマ情報を文字列化\n",
    "        account_schema_str = self.account_schema[['column_name', 'data_type', 'description']].to_string()\n",
    "        opportunity_schema_str = self.opportunity_schema[['column_name', 'data_type', 'description']].to_string()\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        あなたはBigQueryのSQLエキスパートです。\n",
    "        以下のテーブルスキーマを使用して、ユーザーの質問に答えるSQLクエリを生成してください。\n",
    "        \n",
    "        利用可能なテーブル:\n",
    "        1. `esperanto-drawer-prod.dm_business_planning.salesforce_account_mart`\n",
    "        スキーマ:\n",
    "        {account_schema_str[:2000]}  # 最初の2000文字のみ\n",
    "        \n",
    "        2. `esperanto-drawer-prod.dm_business_planning.salesforce_opportunity_mart`\n",
    "        スキーマ:\n",
    "        {opportunity_schema_str[:2000]}  # 最初の2000文字のみ\n",
    "        \n",
    "        重要な注意事項:\n",
    "        - 日付フィールドは TIMESTAMP 型です\n",
    "        - 金額フィールドは Amount, AnnualRevenue などです\n",
    "        - ステージ名は StageName フィールドです\n",
    "        - 日本語のカラム説明を参考にしてください\n",
    "        - LIMIT 1000 を必ず付けてください（大量データ防止）\n",
    "        - JOINする場合は AccountId で結合してください\n",
    "        \n",
    "        ユーザーの質問: {natural_language_query}\n",
    "        \n",
    "        SQLクエリのみを返してください。説明は不要です。\n",
    "        SQLは```sql と ``` で囲んでください。\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.model.generate_content(prompt)\n",
    "        \n",
    "        # SQLを抽出\n",
    "        sql = response.text\n",
    "        if '```sql' in sql:\n",
    "            sql = sql.split('```sql')[1].split('```')[0].strip()\n",
    "        elif '```' in sql:\n",
    "            sql = sql.split('```')[1].split('```')[0].strip()\n",
    "            \n",
    "        return sql\n",
    "    \n",
    "    def execute_query(self, sql: str) -> pd.DataFrame:\n",
    "        \"\"\"SQLを実行してDataFrameを返す\"\"\"\n",
    "        try:\n",
    "            # ドライラン\n",
    "            job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "            dry_run_job = self.client.query(sql, job_config=job_config)\n",
    "            \n",
    "            # 処理バイト数を確認\n",
    "            print(f\"処理予定バイト数: {dry_run_job.total_bytes_processed:,} bytes\")\n",
    "            print(f\"処理予定GB: {dry_run_job.total_bytes_processed / 1e9:.2f} GB\")\n",
    "            \n",
    "            # 実際に実行\n",
    "            query_job = self.client.query(sql)\n",
    "            df = query_job.to_dataframe()\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"エラー: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def analyze(self, natural_language_query: str) -> Dict:\n",
    "        \"\"\"自然言語クエリを分析して結果を返す\"\"\"\n",
    "        print(f\"質問: {natural_language_query}\")\n",
    "        print(\"\\nSQL生成中...\")\n",
    "        \n",
    "        # SQL生成\n",
    "        sql = self.generate_sql(natural_language_query)\n",
    "        print(f\"\\n生成されたSQL:\\n{sql}\")\n",
    "        \n",
    "        # SQL実行\n",
    "        print(\"\\nSQL実行中...\")\n",
    "        df = self.execute_query(sql)\n",
    "        \n",
    "        if df.empty:\n",
    "            return {\n",
    "                'query': natural_language_query,\n",
    "                'sql': sql,\n",
    "                'data': df,\n",
    "                'summary': 'データが取得できませんでした'\n",
    "            }\n",
    "        \n",
    "        # 結果のサマリーを生成\n",
    "        summary = self.generate_summary(natural_language_query, df)\n",
    "        \n",
    "        return {\n",
    "            'query': natural_language_query,\n",
    "            'sql': sql,\n",
    "            'data': df,\n",
    "            'summary': summary\n",
    "        }\n",
    "    \n",
    "    def generate_summary(self, query: str, df: pd.DataFrame) -> str:\n",
    "        \"\"\"結果のサマリーを生成\"\"\"\n",
    "        \n",
    "        # DataFrameの情報を文字列化（最大100行）\n",
    "        df_str = df.head(100).to_string()\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        以下のデータ分析結果を日本語で要約してください。\n",
    "        \n",
    "        元の質問: {query}\n",
    "        \n",
    "        結果データ（最大100行）:\n",
    "        {df_str[:3000]}  # 最初の3000文字のみ\n",
    "        \n",
    "        データ統計:\n",
    "        - 行数: {len(df)}\n",
    "        - カラム数: {len(df.columns)}\n",
    "        \n",
    "        以下の観点で要約してください：\n",
    "        1. 主要な発見・インサイト\n",
    "        2. 数値的な傾向\n",
    "        3. 特筆すべきポイント\n",
    "        \n",
    "        簡潔に3-5文で要約してください。\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "# アナライザーのインスタンス作成\n",
    "analyzer = NLToBigQueryAnalyzer(client, model)\n",
    "print(\"アナライザー初期化完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 分析実行関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(question: str, show_chart: bool = True):\n",
    "    \"\"\"自然言語で分析を実行\"\"\"\n",
    "    \n",
    "    # 分析実行\n",
    "    result = analyzer.analyze(question)\n",
    "    \n",
    "    # 結果表示\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"📊 分析結果\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\n📝 サマリー:\\n{result['summary']}\")\n",
    "    \n",
    "    print(f\"\\n📈 データ（上位10行）:\")\n",
    "    display(result['data'].head(10))\n",
    "    \n",
    "    # グラフ表示（可能な場合）\n",
    "    if show_chart and not result['data'].empty:\n",
    "        df = result['data']\n",
    "        \n",
    "        # 数値カラムを特定\n",
    "        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        \n",
    "        if len(numeric_cols) > 0 and len(df) > 1:\n",
    "            # 最初の数値カラムでグラフ作成\n",
    "            if len(df) <= 20:  # 20行以下なら棒グラフ\n",
    "                fig = px.bar(\n",
    "                    df.head(20), \n",
    "                    y=numeric_cols[0],\n",
    "                    x=df.index if df.index.name else range(len(df)),\n",
    "                    title=f\"{question}の結果\"\n",
    "                )\n",
    "            else:  # それ以上なら線グラフ\n",
    "                fig = px.line(\n",
    "                    df.head(100),\n",
    "                    y=numeric_cols[0],\n",
    "                    x=df.index if df.index.name else range(len(df)),\n",
    "                    title=f\"{question}の結果\"\n",
    "                )\n",
    "            \n",
    "            fig.show()\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"分析関数の準備完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 分析例の実行\n",
    "\n",
    "以下のセルで自然言語による分析を実行できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析例1: 売上上位の企業\n",
    "result1 = run_analysis(\"年間売上が最も高い上位10社を教えて\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析例2: 商談の分析\n",
    "result2 = run_analysis(\"2024年のClosedWonの商談金額の合計を月別に集計して\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析例3: 業界別分析\n",
    "result3 = run_analysis(\"業界別の企業数と平均従業員数を教えて\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析例4: 商談パイプライン\n",
    "result4 = run_analysis(\"現在進行中の商談をステージ別に金額集計して\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析例5: 顧客セグメント分析\n",
    "result5 = run_analysis(\"ENTフラグがTrueの企業の商談の勝率を計算して\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. インタラクティブな分析\n",
    "\n",
    "自由に質問を入力して分析できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自由に質問を入力\n",
    "question = input(\"分析したい内容を自然言語で入力してください: \")\n",
    "result = run_analysis(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 複数質問の一括分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 複数の質問を一括で分析\n",
    "questions = [\n",
    "    \"MIDフラグがTrueの企業数は？\",\n",
    "    \"2024年の新規商談数を月別に集計\",\n",
    "    \"Company_FitがHighの企業の特徴は？\",\n",
    "    \"商談の平均クローズ期間は？\",\n",
    "    \"地域別の企業分布を教えて\"\n",
    "]\n",
    "\n",
    "results = {}\n",
    "for q in questions:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"分析中: {q}\")\n",
    "    print('='*60)\n",
    "    try:\n",
    "        results[q] = run_analysis(q, show_chart=False)\n",
    "    except Exception as e:\n",
    "        print(f\"エラー: {e}\")\n",
    "        results[q] = None\n",
    "\n",
    "# 結果サマリー\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 全体サマリー\")\n",
    "print(\"=\"*60)\n",
    "for q, r in results.items():\n",
    "    if r:\n",
    "        print(f\"\\n【{q}】\")\n",
    "        print(r['summary'][:200] + \"...\" if len(r['summary']) > 200 else r['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 結果のエクスポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析結果をCSVとしてダウンロード\n",
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "def export_results(result_dict, filename=\"analysis_result.csv\"):\n",
    "    \"\"\"分析結果をCSVファイルとしてエクスポート\"\"\"\n",
    "    if result_dict and 'data' in result_dict and not result_dict['data'].empty:\n",
    "        # DataFrameをCSVに変換\n",
    "        result_dict['data'].to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"✅ {filename} を作成しました\")\n",
    "        \n",
    "        # ダウンロード\n",
    "        files.download(filename)\n",
    "    else:\n",
    "        print(\"エクスポートするデータがありません\")\n",
    "\n",
    "# 最後の分析結果をエクスポート\n",
    "if 'result' in locals():\n",
    "    export_results(result, \"last_analysis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. よく使う分析テンプレート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# よく使う分析のテンプレート\n",
    "analysis_templates = {\n",
    "    \"営業パフォーマンス\": [\n",
    "        \"今月のClosedWon商談の合計金額は？\",\n",
    "        \"営業担当者別の商談成約率を計算して\",\n",
    "        \"平均商談期間をステージ別に集計\"\n",
    "    ],\n",
    "    \"顧客分析\": [\n",
    "        \"従業員数1000人以上の大企業リストを表示\",\n",
    "        \"過去1年間で最も取引金額が多い上位20社\",\n",
    "        \"業界別の顧客分布と平均取引額\"\n",
    "    ],\n",
    "    \"パイプライン分析\": [\n",
    "        \"現在のパイプライン総額をステージ別に表示\",\n",
    "        \"今四半期にクローズ予定の商談リスト\",\n",
    "        \"商談の勝率を金額レンジ別に分析\"\n",
    "    ],\n",
    "    \"トレンド分析\": [\n",
    "        \"過去12ヶ月の新規商談数の推移\",\n",
    "        \"月別の受注金額トレンド\",\n",
    "        \"新規顧客獲得数の四半期別推移\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# テンプレート選択\n",
    "print(\"利用可能なテンプレート:\")\n",
    "for i, category in enumerate(analysis_templates.keys(), 1):\n",
    "    print(f\"{i}. {category}\")\n",
    "\n",
    "# カテゴリ選択\n",
    "category_num = int(input(\"\\nカテゴリ番号を選択 (1-4): \"))\n",
    "selected_category = list(analysis_templates.keys())[category_num - 1]\n",
    "\n",
    "print(f\"\\n{selected_category}の分析を実行します\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 選択したカテゴリの分析を実行\n",
    "for question in analysis_templates[selected_category]:\n",
    "    print(f\"\\n▶ {question}\")\n",
    "    try:\n",
    "        result = run_analysis(question, show_chart=True)\n",
    "    except Exception as e:\n",
    "        print(f\"エラー: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. カスタムダッシュボード生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.subplots as sp\n",
    "\n",
    "def create_dashboard():\n",
    "    \"\"\"複数の分析結果を組み合わせたダッシュボードを作成\"\"\"\n",
    "    \n",
    "    # 4つの主要分析を実行\n",
    "    analyses = {\n",
    "        \"月別売上\": \"2024年の月別受注金額を集計\",\n",
    "        \"ステージ別商談\": \"現在の商談をステージ別に件数集計\",\n",
    "        \"業界別顧客\": \"業界別の顧客数を上位10件\",\n",
    "        \"商談勝率\": \"過去6ヶ月の月別商談勝率\"\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for title, query in analyses.items():\n",
    "        try:\n",
    "            print(f\"分析中: {title}\")\n",
    "            results[title] = analyzer.analyze(query)\n",
    "        except Exception as e:\n",
    "            print(f\"エラー ({title}): {e}\")\n",
    "            results[title] = None\n",
    "    \n",
    "    # ダッシュボード作成\n",
    "    fig = sp.make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=list(analyses.keys()),\n",
    "        specs=[\n",
    "            [{'type': 'bar'}, {'type': 'bar'}],\n",
    "            [{'type': 'bar'}, {'type': 'scatter'}]\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 各グラフを追加\n",
    "    positions = [(1, 1), (1, 2), (2, 1), (2, 2)]\n",
    "    \n",
    "    for (title, result), (row, col) in zip(results.items(), positions):\n",
    "        if result and not result['data'].empty:\n",
    "            df = result['data'].head(20)\n",
    "            \n",
    "            # 最初のカラムをX軸、2番目の数値カラムをY軸として使用\n",
    "            if len(df.columns) >= 2:\n",
    "                x_col = df.columns[0]\n",
    "                \n",
    "                # 数値カラムを探す\n",
    "                numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "                if len(numeric_cols) > 0:\n",
    "                    y_col = numeric_cols[0]\n",
    "                    \n",
    "                    if row == 2 and col == 2:  # 最後は線グラフ\n",
    "                        fig.add_trace(\n",
    "                            go.Scatter(\n",
    "                                x=df[x_col].astype(str),\n",
    "                                y=df[y_col],\n",
    "                                mode='lines+markers',\n",
    "                                name=title\n",
    "                            ),\n",
    "                            row=row, col=col\n",
    "                        )\n",
    "                    else:  # その他は棒グラフ\n",
    "                        fig.add_trace(\n",
    "                            go.Bar(\n",
    "                                x=df[x_col].astype(str),\n",
    "                                y=df[y_col],\n",
    "                                name=title\n",
    "                            ),\n",
    "                            row=row, col=col\n",
    "                        )\n",
    "    \n",
    "    # レイアウト設定\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        showlegend=False,\n",
    "        title_text=\"Salesforceデータ分析ダッシュボード\",\n",
    "        title_font_size=20\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ダッシュボード作成\n",
    "dashboard_results = create_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 分析履歴の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析履歴を保存\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# 分析履歴クラス\n",
    "class AnalysisHistory:\n",
    "    def __init__(self):\n",
    "        self.history = []\n",
    "    \n",
    "    def add(self, query, sql, result_shape, summary):\n",
    "        self.history.append({\n",
    "            'timestamp': datetime.now(),\n",
    "            'query': query,\n",
    "            'sql': sql,\n",
    "            'result_shape': result_shape,\n",
    "            'summary': summary\n",
    "        })\n",
    "    \n",
    "    def show_history(self, last_n=10):\n",
    "        \"\"\"最近の分析履歴を表示\"\"\"\n",
    "        for item in self.history[-last_n:]:\n",
    "            print(f\"\\n📅 {item['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "            print(f\"❓ 質問: {item['query']}\")\n",
    "            print(f\"📊 結果: {item['result_shape']}\")\n",
    "            print(f\"📝 サマリー: {item['summary'][:100]}...\")\n",
    "    \n",
    "    def save(self, filename='analysis_history.pkl'):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self.history, f)\n",
    "        print(f\"履歴を {filename} に保存しました\")\n",
    "    \n",
    "    def load(self, filename='analysis_history.pkl'):\n",
    "        try:\n",
    "            with open(filename, 'rb') as f:\n",
    "                self.history = pickle.load(f)\n",
    "            print(f\"履歴を {filename} から読み込みました\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"履歴ファイルが見つかりません\")\n",
    "\n",
    "# 履歴インスタンス作成\n",
    "history = AnalysisHistory()\n",
    "\n",
    "# これまでの分析を履歴に追加（もし結果があれば）\n",
    "if 'results' in locals():\n",
    "    for q, r in results.items():\n",
    "        if r:\n",
    "            history.add(\n",
    "                query=r['query'],\n",
    "                sql=r['sql'],\n",
    "                result_shape=str(r['data'].shape) if 'data' in r else 'N/A',\n",
    "                summary=r.get('summary', 'N/A')\n",
    "            )\n",
    "\n",
    "# 履歴表示\n",
    "print(\"=== 分析履歴 ===\")\n",
    "history.show_history()\n",
    "\n",
    "# 履歴保存\n",
    "history.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "このノートブックでは、以下の機能を提供しています：\n",
    "\n",
    "1. **自然言語でのクエリ**: 日本語でデータに関する質問をするだけで分析可能\n",
    "2. **自動SQL生成**: Gemini APIがスキーマを理解してSQLを生成\n",
    "3. **結果の可視化**: Plotlyによる自動グラフ生成\n",
    "4. **サマリー生成**: AIによる分析結果の要約\n",
    "5. **ダッシュボード**: 複数分析の統合表示\n",
    "6. **履歴管理**: 分析履歴の保存と参照\n",
    "\n",
    "### 使い方のヒント\n",
    "\n",
    "- 具体的な数値や期間を含めると、より正確な分析ができます\n",
    "- 「上位10件」「月別」「業界別」などの集計キーワードを使うと効果的です\n",
    "- 複雑な分析は段階的に実行することをお勧めします\n",
    "\n",
    "### 注意事項\n",
    "\n",
    "- 大量データのクエリはコストがかかるため、LIMIT句が自動追加されます\n",
    "- Gemini APIの利用制限に注意してください\n",
    "- 機密情報の取り扱いには十分注意してください"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}