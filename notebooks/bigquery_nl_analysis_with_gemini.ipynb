{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery Natural Language Analysis with Gemini\n",
    "\n",
    "このノートブックでは、Gemini APIを使用してBigQueryのSalesforceデータを自然言語で分析します。\n",
    "\n",
    "## 主な機能\n",
    "- 🗣️ **自然言語でのクエリ**: 日本語でデータに関する質問をするだけで分析可能\n",
    "- 🤖 **自動SQL生成**: Gemini APIがスキーマを理解してSQLを生成\n",
    "- 📊 **結果の可視化**: Plotlyによる自動グラフ生成\n",
    "- 📝 **サマリー生成**: AIによる分析結果の要約\n",
    "- 📈 **ダッシュボード**: 複数分析の統合表示\n",
    "- 💾 **履歴管理**: 分析履歴の保存と参照\n",
    "\n",
    "## 使用モデル（2025年1月最新）\n",
    "- **Gemini 2.5 Pro** (gemini-2.5-pro-exp-0117): データ分析最適化モデル\n",
    "- **Gemini 2.5 Flash** (gemini-2.5-flash-exp-0117): 高速バランス版\n",
    "- **Gemini 2.0 Flash** (gemini-2.0-flash-exp-01-21): 超高速処理版"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境設定とライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリをインストール\n",
    "!pip install -q google-cloud-bigquery google-cloud-bigquery-storage pandas db-dtypes\n",
    "!pip install -q google-generativeai\n",
    "!pip install -q plotly matplotlib seaborn\n",
    "!pip install -q pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Google Cloud認証とAPI設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Google Cloud認証（Colab環境の場合）\n",
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    print('✅ Google Cloud認証完了')\n",
    "except ImportError:\n",
    "    print('ℹ️ ローカル環境で実行中 - gcloud auth を使用')\n",
    "\n",
    "# BigQueryクライアントの初期化\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import GoogleCloudError\n",
    "\n",
    "PROJECT_ID = 'esperanto-drawer-prod'\n",
    "DATASET_ID = 'dm_business_planning'\n",
    "\n",
    "try:\n",
    "    client = bigquery.Client(project=PROJECT_ID)\n",
    "    print(f'✅ BigQueryクライアント初期化完了: {PROJECT_ID}')\n",
    "except Exception as e:\n",
    "    print(f'❌ BigQueryクライアント初期化エラー: {e}')\n",
    "    client = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gemini API設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# Gemini API キーの設定\n",
    "def setup_gemini_api():\n",
    "    \"\"\"Gemini APIキーを設定し、モデルを初期化\"\"\"\n",
    "    api_key = None\n",
    "    \n",
    "    # 1. Colabシークレットから取得を試みる\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        api_key = userdata.get('GEMINI_API_KEY')\n",
    "        print('✅ Colabシークレットから API Key を取得しました')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # 2. 環境変数から取得を試みる\n",
    "    if not api_key:\n",
    "        api_key = os.getenv('GEMINI_API_KEY')\n",
    "        if api_key:\n",
    "            print('✅ 環境変数から API Key を取得しました')\n",
    "    \n",
    "    # 3. 手動入力\n",
    "    if not api_key:\n",
    "        from getpass import getpass\n",
    "        api_key = getpass('Gemini API Key を入力してください: ')\n",
    "    \n",
    "    genai.configure(api_key=api_key)\n",
    "    \n",
    "    # モデルの初期化（フォールバック付き）\n",
    "    models_to_try = [\n",
    "        ('gemini-2.5-pro-exp-0117', '最新データ分析特化版'),\n",
    "        ('gemini-2.5-flash-exp-0117', '高速バランス版'),\n",
    "        ('gemini-2.0-flash-exp-01-21', '超高速版'),\n",
    "        ('gemini-1.5-pro', '安定版')\n",
    "    ]\n",
    "    \n",
    "    for model_name, description in models_to_try:\n",
    "        try:\n",
    "            model = genai.GenerativeModel(model_name)\n",
    "            print(f'✅ 使用モデル: {model_name} ({description})')\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f'⚠️ {model_name} は利用できません: {e}')\n",
    "            continue\n",
    "    \n",
    "    raise Exception(\"利用可能なGeminiモデルが見つかりません\")\n",
    "\n",
    "# Geminiモデルの初期化\n",
    "model = setup_gemini_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. テーブルスキーマの取得（改良版）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_schema_safe(dataset_id: str, table_id: str) -> pd.DataFrame:\n",
    "    \"\"\"テーブルのスキーマ情報を安全に取得\"\"\"\n",
    "    \n",
    "    # 最も基本的なクエリから始める\n",
    "    queries = [\n",
    "        # Option 1: COLUMN_FIELD_PATHSを使用（推奨）\n",
    "        f\"\"\"\n",
    "        SELECT \n",
    "            column_name,\n",
    "            data_type,\n",
    "            field_path\n",
    "        FROM `{PROJECT_ID}.{dataset_id}.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS`\n",
    "        WHERE table_name = '{table_id}'\n",
    "        ORDER BY column_name\n",
    "        \"\"\",\n",
    "        # Option 2: COLUMNSを使用（フォールバック）\n",
    "        f\"\"\"\n",
    "        SELECT \n",
    "            column_name,\n",
    "            data_type\n",
    "        FROM `{PROJECT_ID}.{dataset_id}.INFORMATION_SCHEMA.COLUMNS`\n",
    "        WHERE table_name = '{table_id}'\n",
    "        ORDER BY column_name\n",
    "        \"\"\",\n",
    "        # Option 3: テーブルから直接スキーマを取得（最終手段）\n",
    "        f\"\"\"\n",
    "        SELECT *\n",
    "        FROM `{PROJECT_ID}.{dataset_id}.{table_id}`\n",
    "        LIMIT 0\n",
    "        \"\"\"\n",
    "    ]\n",
    "    \n",
    "    for i, query in enumerate(queries, 1):\n",
    "        try:\n",
    "            print(f\"試行 {i}/3: スキーマ取得中...\")\n",
    "            if i == 3:\n",
    "                # Option 3の場合は、クエリ結果からスキーマを推定\n",
    "                job = client.query(query)\n",
    "                schema = []\n",
    "                for field in job.schema:\n",
    "                    schema.append({\n",
    "                        'column_name': field.name,\n",
    "                        'data_type': field.field_type,\n",
    "                        'description': field.description or ''\n",
    "                    })\n",
    "                df = pd.DataFrame(schema)\n",
    "            else:\n",
    "                df = client.query(query).to_dataframe()\n",
    "            \n",
    "            # descriptionカラムがない場合は追加\n",
    "            if 'description' not in df.columns:\n",
    "                df['description'] = ''\n",
    "            \n",
    "            print(f\"✅ スキーマ取得成功: {len(df)} カラム\")\n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 試行 {i} 失敗: {str(e)[:100]}\")\n",
    "            continue\n",
    "    \n",
    "    # すべて失敗した場合\n",
    "    print(\"❌ スキーマ取得に失敗しました\")\n",
    "    return pd.DataFrame(columns=['column_name', 'data_type', 'description'])\n",
    "\n",
    "# スキーマ情報を取得\n",
    "print(\"=\" * 50)\n",
    "print(\"📊 Salesforce Account Mart スキーマ取得\")\n",
    "account_schema = get_table_schema_safe(DATASET_ID, 'salesforce_account_mart')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"📊 Salesforce Opportunity Mart スキーマ取得\")\n",
    "opportunity_schema = get_table_schema_safe(DATASET_ID, 'salesforce_opportunity_mart')\n",
    "\n",
    "# 結果表示\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"✅ Account Mart: {len(account_schema)} カラム\")\n",
    "print(f\"✅ Opportunity Mart: {len(opportunity_schema)} カラム\")\n",
    "\n",
    "# 主要カラムを表示\n",
    "if not account_schema.empty:\n",
    "    print(\"\\n📋 Account Mart 主要カラム:\")\n",
    "    display(account_schema.head(10))\n",
    "\n",
    "if not opportunity_schema.empty:\n",
    "    print(\"\\n📋 Opportunity Mart 主要カラム:\")\n",
    "    display(opportunity_schema.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 自然言語→SQL変換クラス（コア機能）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLToBigQueryAnalyzer:\n",
    "    \"\"\"自然言語クエリをBigQuery SQLに変換して実行するクラス\"\"\"\n",
    "    \n",
    "    def __init__(self, client: bigquery.Client, model, \n",
    "                 account_schema: pd.DataFrame, \n",
    "                 opportunity_schema: pd.DataFrame):\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "        self.account_schema = account_schema\n",
    "        self.opportunity_schema = opportunity_schema\n",
    "        self.history = []  # 分析履歴\n",
    "        \n",
    "    def generate_sql(self, natural_language_query: str) -> str:\n",
    "        \"\"\"自然言語クエリからSQLを生成\"\"\"\n",
    "        \n",
    "        # スキーマ情報を文字列化（最大50カラムずつ）\n",
    "        account_cols = self.account_schema[['column_name', 'data_type']].head(50).to_string(index=False)\n",
    "        opportunity_cols = self.opportunity_schema[['column_name', 'data_type']].head(50).to_string(index=False)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        あなたはBigQueryのSQLエキスパートです。\n",
    "        以下のテーブルスキーマを使用して、ユーザーの質問に答えるSQLクエリを生成してください。\n",
    "        \n",
    "        ## 利用可能なテーブル:\n",
    "        \n",
    "        ### 1. `esperanto-drawer-prod.dm_business_planning.salesforce_account_mart`\n",
    "        企業・顧客マスタデータ\n",
    "        主要カラム:\n",
    "        {account_cols}\n",
    "        \n",
    "        ### 2. `esperanto-drawer-prod.dm_business_planning.salesforce_opportunity_mart`\n",
    "        商談・案件データ\n",
    "        主要カラム:\n",
    "        {opportunity_cols}\n",
    "        \n",
    "        ## 重要な注意事項:\n",
    "        - 日付カラムは TIMESTAMP または DATE 型\n",
    "        - 金額カラムは Amount, AnnualRevenue など\n",
    "        - ステージ名は StageName\n",
    "        - 必ず LIMIT 1000 を付ける（大量データ防止）\n",
    "        - JOINする場合は AccountId で結合\n",
    "        - エラーが起きにくいシンプルなクエリを心がける\n",
    "        \n",
    "        ## ユーザーの質問:\n",
    "        {natural_language_query}\n",
    "        \n",
    "        SQLクエリのみを返してください。説明は不要です。\n",
    "        SQLは```sql と ``` で囲んでください。\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            sql = response.text\n",
    "            \n",
    "            # SQLを抽出\n",
    "            if '```sql' in sql:\n",
    "                sql = sql.split('```sql')[1].split('```')[0].strip()\n",
    "            elif '```' in sql:\n",
    "                sql = sql.split('```')[1].split('```')[0].strip()\n",
    "                \n",
    "            return sql\n",
    "        except Exception as e:\n",
    "            print(f\"❌ SQL生成エラー: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def execute_query(self, sql: str) -> Tuple[pd.DataFrame, str]:\n",
    "        \"\"\"SQLを実行してDataFrameを返す\"\"\"\n",
    "        try:\n",
    "            # ドライランでコスト確認\n",
    "            job_config = bigquery.QueryJobConfig(dry_run=True, use_query_cache=False)\n",
    "            dry_run_job = self.client.query(sql, job_config=job_config)\n",
    "            \n",
    "            bytes_processed = dry_run_job.total_bytes_processed\n",
    "            gb_processed = bytes_processed / 1e9\n",
    "            cost_estimate = gb_processed * 5  # $5 per TB\n",
    "            \n",
    "            print(f\"💰 処理予定: {gb_processed:.3f} GB (推定コスト: ${cost_estimate:.4f})\")\n",
    "            \n",
    "            # 実際に実行\n",
    "            query_job = self.client.query(sql)\n",
    "            df = query_job.to_dataframe()\n",
    "            \n",
    "            return df, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            print(f\"❌ クエリ実行エラー: {error_msg[:200]}\")\n",
    "            return pd.DataFrame(), error_msg\n",
    "    \n",
    "    def generate_summary(self, query: str, df: pd.DataFrame) -> str:\n",
    "        \"\"\"結果のサマリーを生成\"\"\"\n",
    "        if df.empty:\n",
    "            return \"データが取得できませんでした。\"\n",
    "        \n",
    "        # DataFrameの統計情報\n",
    "        stats = {\n",
    "            '行数': len(df),\n",
    "            'カラム数': len(df.columns),\n",
    "            'カラム名': list(df.columns)[:10]  # 最初の10カラム\n",
    "        }\n",
    "        \n",
    "        # 数値カラムの基本統計\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            stats['数値カラム'] = list(numeric_cols)[:5]\n",
    "        \n",
    "        # サンプルデータ（最大10行）\n",
    "        sample_data = df.head(10).to_string() if len(df) > 0 else \"データなし\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        以下のデータ分析結果を日本語で要約してください。\n",
    "        \n",
    "        元の質問: {query}\n",
    "        \n",
    "        データ統計:\n",
    "        {json.dumps(stats, ensure_ascii=False, indent=2)}\n",
    "        \n",
    "        サンプルデータ（最大10行）:\n",
    "        {sample_data[:2000]}\n",
    "        \n",
    "        以下の観点で3-5文で要約してください：\n",
    "        1. 主要な発見・インサイト\n",
    "        2. 数値的な傾向\n",
    "        3. ビジネス上の示唆\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            return f\"サマリー生成エラー: {e}\"\n",
    "    \n",
    "    def analyze(self, natural_language_query: str, show_details: bool = True) -> Dict:\n",
    "        \"\"\"自然言語クエリを分析して結果を返す\"\"\"\n",
    "        \n",
    "        result = {\n",
    "            'timestamp': datetime.now(),\n",
    "            'query': natural_language_query,\n",
    "            'sql': None,\n",
    "            'data': pd.DataFrame(),\n",
    "            'error': None,\n",
    "            'summary': None\n",
    "        }\n",
    "        \n",
    "        if show_details:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"🔍 質問: {natural_language_query}\")\n",
    "            print(\"='*60}\")\n",
    "        \n",
    "        # SQL生成\n",
    "        print(\"\\n⏳ SQL生成中...\")\n",
    "        sql = self.generate_sql(natural_language_query)\n",
    "        if not sql:\n",
    "            result['error'] = \"SQL生成に失敗しました\"\n",
    "            return result\n",
    "        \n",
    "        result['sql'] = sql\n",
    "        if show_details:\n",
    "            print(f\"\\n📝 生成されたSQL:\\n{sql}\")\n",
    "        \n",
    "        # SQL実行\n",
    "        print(\"\\n⏳ クエリ実行中...\")\n",
    "        df, error = self.execute_query(sql)\n",
    "        \n",
    "        if error:\n",
    "            result['error'] = error\n",
    "            result['summary'] = f\"エラーが発生しました: {error[:100]}\"\n",
    "        else:\n",
    "            result['data'] = df\n",
    "            print(f\"✅ {len(df)} 行のデータを取得\")\n",
    "            \n",
    "            # サマリー生成\n",
    "            print(\"\\n⏳ サマリー生成中...\")\n",
    "            result['summary'] = self.generate_summary(natural_language_query, df)\n",
    "        \n",
    "        # 履歴に追加\n",
    "        self.history.append(result)\n",
    "        \n",
    "        return result\n",
    "\n",
    "# アナライザーのインスタンス作成\n",
    "if client and model:\n",
    "    analyzer = NLToBigQueryAnalyzer(client, model, account_schema, opportunity_schema)\n",
    "    print(\"\\n✅ アナライザー初期化完了\")\n",
    "else:\n",
    "    print(\"\\n❌ アナライザー初期化失敗（BigQueryまたはGemini APIの設定を確認してください）\")\n",
    "    analyzer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 分析実行と可視化関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def run_analysis(question: str, show_chart: bool = True, chart_type: str = 'auto') -> Dict:\n",
    "    \"\"\"自然言語で分析を実行し、結果を可視化\"\"\"\n",
    "    \n",
    "    if not analyzer:\n",
    "        print(\"❌ アナライザーが初期化されていません\")\n",
    "        return None\n",
    "    \n",
    "    # 分析実行\n",
    "    result = analyzer.analyze(question)\n",
    "    \n",
    "    # 結果表示\n",
    "    if result['summary']:\n",
    "        print(f\"\\n📊 分析結果サマリー:\")\n",
    "        print(result['summary'])\n",
    "    \n",
    "    # データ表示\n",
    "    if not result['data'].empty:\n",
    "        print(f\"\\n📋 データ（上位10行）:\")\n",
    "        display(result['data'].head(10))\n",
    "        \n",
    "        # グラフ表示\n",
    "        if show_chart:\n",
    "            create_visualization(result['data'], question, chart_type)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_visualization(df: pd.DataFrame, title: str, chart_type: str = 'auto'):\n",
    "    \"\"\"データフレームから適切なグラフを自動生成\"\"\"\n",
    "    \n",
    "    if df.empty:\n",
    "        return\n",
    "    \n",
    "    # 数値カラムと非数値カラムを識別\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    \n",
    "    # chart_typeが'auto'の場合、データから最適なグラフタイプを推定\n",
    "    if chart_type == 'auto':\n",
    "        if len(df) <= 20 and len(numeric_cols) > 0:\n",
    "            chart_type = 'bar'\n",
    "        elif len(numeric_cols) >= 2:\n",
    "            chart_type = 'scatter'\n",
    "        elif len(numeric_cols) == 1 and len(df) > 20:\n",
    "            chart_type = 'line'\n",
    "        else:\n",
    "            chart_type = 'table'\n",
    "    \n",
    "    try:\n",
    "        if chart_type == 'bar' and len(numeric_cols) > 0:\n",
    "            # 棒グラフ\n",
    "            x_col = non_numeric_cols[0] if non_numeric_cols else df.index\n",
    "            y_col = numeric_cols[0]\n",
    "            fig = px.bar(df.head(20), x=x_col, y=y_col, title=title)\n",
    "            \n",
    "        elif chart_type == 'line' and len(numeric_cols) > 0:\n",
    "            # 線グラフ\n",
    "            x_col = non_numeric_cols[0] if non_numeric_cols else df.index\n",
    "            y_col = numeric_cols[0]\n",
    "            fig = px.line(df, x=x_col, y=y_col, title=title, markers=True)\n",
    "            \n",
    "        elif chart_type == 'scatter' and len(numeric_cols) >= 2:\n",
    "            # 散布図\n",
    "            fig = px.scatter(df, x=numeric_cols[0], y=numeric_cols[1], title=title)\n",
    "            \n",
    "        elif chart_type == 'pie' and len(numeric_cols) > 0 and len(non_numeric_cols) > 0:\n",
    "            # 円グラフ\n",
    "            fig = px.pie(df.head(10), values=numeric_cols[0], names=non_numeric_cols[0], title=title)\n",
    "            \n",
    "        else:\n",
    "            # テーブル表示\n",
    "            fig = go.Figure(data=[go.Table(\n",
    "                header=dict(values=list(df.columns),\n",
    "                           fill_color='paleturquoise',\n",
    "                           align='left'),\n",
    "                cells=dict(values=[df[col] for col in df.columns],\n",
    "                          fill_color='lavender',\n",
    "                          align='left'))\n",
    "            ])\n",
    "            fig.update_layout(title=title)\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ グラフ生成エラー: {e}\")\n",
    "\n",
    "print(\"✅ 分析・可視化関数の準備完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ダッシュボード生成機能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dashboard(analyses: Dict[str, str] = None):\n",
    "    \"\"\"複数の分析結果を組み合わせたダッシュボードを作成\"\"\"\n",
    "    \n",
    "    if not analyzer:\n",
    "        print(\"❌ アナライザーが初期化されていません\")\n",
    "        return None\n",
    "    \n",
    "    # デフォルトの分析セット\n",
    "    if analyses is None:\n",
    "        analyses = {\n",
    "            \"月別売上トレンド\": \"2024年の月別受注金額を集計\",\n",
    "            \"ステージ別商談\": \"現在の商談をステージ別に件数と金額で集計\",\n",
    "            \"顧客セグメント\": \"ENT、MID、SMBフラグ別の顧客数\",\n",
    "            \"業界別分析\": \"業界別の顧客数上位10件\"\n",
    "        }\n",
    "    \n",
    "    results = {}\n",
    "    print(\"📊 ダッシュボード生成中...\\n\")\n",
    "    \n",
    "    # 各分析を実行\n",
    "    for title, query in analyses.items():\n",
    "        print(f\"⏳ 分析中: {title}\")\n",
    "        try:\n",
    "            result = analyzer.analyze(query, show_details=False)\n",
    "            results[title] = result\n",
    "            if not result['data'].empty:\n",
    "                print(f\"✅ {title}: {len(result['data'])} 行取得\")\n",
    "            else:\n",
    "                print(f\"⚠️ {title}: データなし\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {title}: エラー - {e}\")\n",
    "            results[title] = None\n",
    "    \n",
    "    # ダッシュボード作成\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=list(analyses.keys()),\n",
    "        specs=[\n",
    "            [{'type': 'bar'}, {'type': 'bar'}],\n",
    "            [{'type': 'bar'}, {'type': 'scatter'}]\n",
    "        ],\n",
    "        vertical_spacing=0.15,\n",
    "        horizontal_spacing=0.15\n",
    "    )\n",
    "    \n",
    "    # 各グラフを配置\n",
    "    positions = [(1, 1), (1, 2), (2, 1), (2, 2)]\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "    \n",
    "    for (title, result), (row, col), color in zip(results.items(), positions, colors):\n",
    "        if result and not result['data'].empty:\n",
    "            df = result['data'].head(20)\n",
    "            \n",
    "            # カラムを特定\n",
    "            numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "            non_numeric_cols = df.select_dtypes(exclude=[np.number]).columns\n",
    "            \n",
    "            if len(numeric_cols) > 0:\n",
    "                y_col = numeric_cols[0]\n",
    "                x_col = non_numeric_cols[0] if len(non_numeric_cols) > 0 else df.index\n",
    "                \n",
    "                if row == 2 and col == 2:  # 最後は散布図/線グラフ\n",
    "                    fig.add_trace(\n",
    "                        go.Scatter(\n",
    "                            x=df[x_col] if isinstance(x_col, str) else x_col,\n",
    "                            y=df[y_col],\n",
    "                            mode='lines+markers',\n",
    "                            name=title,\n",
    "                            marker=dict(color=color)\n",
    "                        ),\n",
    "                        row=row, col=col\n",
    "                    )\n",
    "                else:  # 棒グラフ\n",
    "                    fig.add_trace(\n",
    "                        go.Bar(\n",
    "                            x=df[x_col] if isinstance(x_col, str) else x_col,\n",
    "                            y=df[y_col],\n",
    "                            name=title,\n",
    "                            marker=dict(color=color)\n",
    "                        ),\n",
    "                        row=row, col=col\n",
    "                    )\n",
    "    \n",
    "    # レイアウト設定\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        showlegend=False,\n",
    "        title=dict(\n",
    "            text=\"<b>Salesforce データ分析ダッシュボード</b>\",\n",
    "            font=dict(size=20),\n",
    "            x=0.5,\n",
    "            xanchor='center'\n",
    "        ),\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    # 軸ラベルを回転\n",
    "    fig.update_xaxes(tickangle=45)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"✅ ダッシュボード機能の準備完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 履歴管理機能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import List\n",
    "\n",
    "class AnalysisHistory:\n",
    "    \"\"\"分析履歴の管理クラス\"\"\"\n",
    "    \n",
    "    def __init__(self, analyzer: NLToBigQueryAnalyzer = None):\n",
    "        self.analyzer = analyzer\n",
    "        self.history = analyzer.history if analyzer else []\n",
    "    \n",
    "    def show_history(self, last_n: int = 10):\n",
    "        \"\"\"最近の分析履歴を表示\"\"\"\n",
    "        if not self.history:\n",
    "            print(\"📭 履歴がありません\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n📚 分析履歴（最新{last_n}件）\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        for i, item in enumerate(self.history[-last_n:], 1):\n",
    "            print(f\"\\n[{i}] {item['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "            print(f\"   質問: {item['query']}\")\n",
    "            if not item['data'].empty:\n",
    "                print(f\"   結果: {len(item['data'])} 行 × {len(item['data'].columns)} カラム\")\n",
    "            else:\n",
    "                print(f\"   結果: データなし\")\n",
    "            if item['error']:\n",
    "                print(f\"   エラー: {item['error'][:100]}\")\n",
    "    \n",
    "    def get_history_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"履歴をDataFrameとして取得\"\"\"\n",
    "        if not self.history:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        history_data = []\n",
    "        for item in self.history:\n",
    "            history_data.append({\n",
    "                'timestamp': item['timestamp'],\n",
    "                'query': item['query'],\n",
    "                'rows': len(item['data']) if not item['data'].empty else 0,\n",
    "                'columns': len(item['data'].columns) if not item['data'].empty else 0,\n",
    "                'has_error': item['error'] is not None\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(history_data)\n",
    "    \n",
    "    def save(self, filename: str = 'analysis_history.pkl'):\n",
    "        \"\"\"履歴をファイルに保存\"\"\"\n",
    "        try:\n",
    "            with open(filename, 'wb') as f:\n",
    "                pickle.dump(self.history, f)\n",
    "            print(f\"💾 履歴を {filename} に保存しました\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 保存エラー: {e}\")\n",
    "    \n",
    "    def load(self, filename: str = 'analysis_history.pkl'):\n",
    "        \"\"\"履歴をファイルから読み込み\"\"\"\n",
    "        try:\n",
    "            with open(filename, 'rb') as f:\n",
    "                self.history = pickle.load(f)\n",
    "            print(f\"📂 履歴を {filename} から読み込みました（{len(self.history)}件）\")\n",
    "            if self.analyzer:\n",
    "                self.analyzer.history = self.history\n",
    "        except FileNotFoundError:\n",
    "            print(f\"⚠️ ファイル {filename} が見つかりません\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 読み込みエラー: {e}\")\n",
    "    \n",
    "    def export_to_csv(self, filename: str = 'analysis_history.csv'):\n",
    "        \"\"\"履歴をCSVファイルにエクスポート\"\"\"\n",
    "        df = self.get_history_dataframe()\n",
    "        if not df.empty:\n",
    "            df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "            print(f\"📊 履歴を {filename} にエクスポートしました\")\n",
    "        else:\n",
    "            print(\"📭 エクスポートする履歴がありません\")\n",
    "\n",
    "# 履歴管理インスタンスの作成\n",
    "if analyzer:\n",
    "    history_manager = AnalysisHistory(analyzer)\n",
    "    print(\"✅ 履歴管理機能の準備完了\")\n",
    "else:\n",
    "    history_manager = None\n",
    "    print(\"⚠️ 履歴管理機能は利用できません（アナライザーが未初期化）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 分析例の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析例1: 売上上位企業\n",
    "result1 = run_analysis(\"年間売上が最も高い上位10社を教えて\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析例2: 月別トレンド\n",
    "result2 = run_analysis(\"2024年の月別商談数の推移を見せて\", chart_type='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析例3: セグメント分析\n",
    "result3 = run_analysis(\"ENT、MID、SMBフラグ別の企業数と平均売上\", chart_type='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. インタラクティブな分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自由に質問を入力して分析\n",
    "question = input(\"分析したい内容を自然言語で入力してください: \")\n",
    "if question:\n",
    "    result = run_analysis(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ダッシュボード生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カスタムダッシュボードの生成\n",
    "dashboard_results = create_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 履歴の管理と表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 履歴を表示\n",
    "if history_manager:\n",
    "    history_manager.show_history(last_n=5)\n",
    "    \n",
    "    # 履歴をDataFrameとして取得\n",
    "    history_df = history_manager.get_history_dataframe()\n",
    "    if not history_df.empty:\n",
    "        print(\"\\n📊 履歴統計:\")\n",
    "        display(history_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 履歴を保存\n",
    "if history_manager:\n",
    "    history_manager.save('analysis_history.pkl')\n",
    "    history_manager.export_to_csv('analysis_history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. 分析テンプレート集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# よく使う分析のテンプレート\n",
    "analysis_templates = {\n",
    "    \"営業パフォーマンス\": [\n",
    "        \"今月のClosedWonの商談金額合計は？\",\n",
    "        \"商談の平均クローズ期間をステージ別に集計\",\n",
    "        \"今四半期の新規商談数と金額\"\n",
    "    ],\n",
    "    \"顧客分析\": [\n",
    "        \"従業員数1000人以上の大企業リスト上位20社\",\n",
    "        \"業界別の顧客数と平均売上\",\n",
    "        \"地域別の顧客分布\"\n",
    "    ],\n",
    "    \"トレンド分析\": [\n",
    "        \"過去12ヶ月の月別売上推移\",\n",
    "        \"四半期別の新規顧客獲得数\",\n",
    "        \"商談ステージ別の推移\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# テンプレート選択と実行\n",
    "print(\"📋 利用可能なテンプレート:\")\n",
    "for i, category in enumerate(analysis_templates.keys(), 1):\n",
    "    print(f\"{i}. {category}\")\n",
    "\n",
    "try:\n",
    "    choice = int(input(\"\\nカテゴリ番号を選択 (1-3): \"))\n",
    "    if 1 <= choice <= 3:\n",
    "        selected_category = list(analysis_templates.keys())[choice - 1]\n",
    "        print(f\"\\n選択: {selected_category}\")\n",
    "        \n",
    "        for question in analysis_templates[selected_category]:\n",
    "            print(f\"\\n▶ {question}\")\n",
    "            try:\n",
    "                result = run_analysis(question, show_chart=True)\n",
    "            except Exception as e:\n",
    "                print(f\"❌ エラー: {e}\")\n",
    "except:\n",
    "    print(\"スキップします\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "\n",
    "このノートブックでは、以下の機能を実装しました：\n",
    "\n",
    "✅ **実装済み機能**\n",
    "1. 🗣️ **自然言語でのクエリ** - 日本語でデータに関する質問をするだけで分析可能\n",
    "2. 🤖 **自動SQL生成** - Gemini APIがスキーマを理解してSQLを生成\n",
    "3. 📊 **結果の可視化** - Plotlyによる自動グラフ生成\n",
    "4. 📝 **サマリー生成** - AIによる分析結果の要約\n",
    "5. 📈 **ダッシュボード** - 複数分析の統合表示\n",
    "6. 💾 **履歴管理** - 分析履歴の保存と参照\n",
    "\n",
    "### 使い方のヒント\n",
    "- 具体的な数値や期間を含めると、より正確な分析ができます\n",
    "- 「上位10件」「月別」「業界別」などの集計キーワードを使うと効果的です\n",
    "- 複雑な分析は段階的に実行することをお勧めします\n",
    "\n",
    "### トラブルシューティング\n",
    "- **スキーマ取得エラー**: INFORMATION_SCHEMAの権限を確認\n",
    "- **SQL実行エラー**: クエリの構文とテーブル名を確認\n",
    "- **Gemini APIエラー**: API キーと利用制限を確認\n",
    "\n",
    "### 注意事項\n",
    "- 大量データのクエリはコストがかかるため、LIMIT句が自動追加されます\n",
    "- Gemini APIの利用制限に注意してください\n",
    "- 機密情報の取り扱いには十分注意してください"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}